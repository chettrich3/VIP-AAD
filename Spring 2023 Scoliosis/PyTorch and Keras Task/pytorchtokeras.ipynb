{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsI_NN_YcfEk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# model will infer the input shape based on the call\n",
        "\n",
        "# we do not know the input shape\n",
        "model = keras.Sequential()\n",
        "\n",
        "# NOTE: Whenever PyTorch uses padding (i.e. padding = (3,3)), you need to use keras.layers.ZeroPadding2D(padding=(3,3)) to replicate those effects\n",
        "\n",
        "### BASE NETWORK\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding=\"same\", use_bias=False)) # conv1\n",
        "model.add(keras.layers.BatchNormalization(axis=3, momentum=0.1, epsilon=1e-05, center=True, scale=True)) # bn1\n",
        "model.add(keras.layers.Activation('relu')) # relu\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"same\", data_format=\"channels_last\")) # maxpool\n",
        "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False)) # conv2\n",
        "model.add(keras.layers.BatchNormalization(axis=3, momentum=0.1, epsilon=1e-05, center=True, scale=True)) # bn2\n",
        "\n",
        "### LAYER 2 DOWNSAMPLE\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2), padding='valid', use_bias=False)) # layer_2_zero\n",
        "model.add(keras.layers.BatchNormalization(axis=3, momentum=0.1, epsilon=1e-05, center=True, scale=True)) # layer_2_one\n",
        "\n",
        "### LAYER 3 DOWNSAMPLE\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(2, 2), padding='valid', use_bias=False)) # layer_3_zero\n",
        "model.add(keras.layers.BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True)) # layer_3_one\n",
        "\n",
        "### LAYER 4 DOWNSAMPLE\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=512, kernel_size=(1, 1), strides=(2, 2), padding='valid', use_bias=False)) # layer_4_zero\n",
        "model.add(keras.layers.BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')) # layer_4_zero\n",
        "\n",
        "### DEC_C4 - UP\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same') # dec_c4_up_zero\n",
        "model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')) # dec_c4_up_one\n",
        "model.add(Activation('relu')) # dec_c4_up_two\n",
        "\n",
        "### DEC_C4 - CAT_CONV\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(1, 1), strides=(1, 1), padding='valid', use_bias=True)) # dec_c4_cat_conv_zero\n",
        "model.add(BatchNormalization(epsilon=1e-05, momentum=0.1, center=True, scale=True)) # dec_c4_cat_conv_one\n",
        "model.add(ReLU()) # dec_c4_cat_conv_two\n",
        "\n",
        "### HM\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same') # hm_zero\n",
        "model.add(ReLU()) # hm_one\n",
        "model.add(Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1), padding='valid', use_bias=True)) # hm_two\n",
        "\n",
        "### REG\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=True)) # reg_zero\n",
        "model.add(ReLU()) # reg_one\n",
        "model.add(Conv2D(filters=2, kernel_size=(1, 1), strides=(1, 1), use_bias=True)) # reg_two\n",
        "\n",
        "### WH\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(7, 7), strides=(1, 1), padding='same', activation='relu', use_bias=True)) # wh_zero\n",
        "model.add(ReLU()) # wh_one\n",
        "model.add(Conv2D(filters=8, kernel_size=(7, 7), strides=(1, 1), padding='same', activation=None)) # wh_two\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# BatchNormalization weights are two dimensional while in Conv2D the weights are four dimensional.\n",
        "# ReLU does not have any weights, if the numbers are less than zero it makes them zero, if the numbers are greater than zero it does not touch them\n",
        "# whenever a layer gets trained, it does a lot of math, and the weights are the coefficinets to the math being done\n",
        "# if the weights are not copied over then the results are going to be completely different"
      ],
      "metadata": {
        "id": "5sClOGfxj_7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85ef3b2-0455-42b7-af5c-0900e0a5cb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 1, 1, 64)          200704    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1, 1, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 1, 1, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200,960\n",
            "Trainable params: 200,832\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Tq6D-_lj1I",
        "outputId": "a8cdd4d2-4fc4-4a8f-c558-759c725c79dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "    ### BASE NETWORK\n",
        "\n",
        "    self.conv1 = nn.Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding = (3, 3), bias = False)\n",
        "    self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "    self.conv2 = nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    self.bn2 = BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "    ### LAYER 2 DOWNSAMPLE\n",
        "\n",
        "    self.layer_2_zero = nn.Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "    self.layer_2_one = BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "    ### LAYER 3 DOWNSAMPLE\n",
        "\n",
        "    self.layer_3_zero = nn.Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "    self.layer_3_one = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "    ### LAYER 4 DOWNSAMPLE\n",
        "\n",
        "    self.layer_4_zero = nn.Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "    self.layer_4_one = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "    ### DEC_C4 - UP\n",
        "\n",
        "    self.dec_c4_up_zero = Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    self.dec_c4_up_one = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    self.dec_c4_up_two = ReLU(inplace)\n",
        "\n",
        "    ### DEC_C4 - CAT_CONV\n",
        "\n",
        "    self.dec_c4_cat_conv_zero = Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
        "    self.dec_c4_cat_conv_one = BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    self.dec_c4_cat_conv_two = ReLU(inplace)\n",
        "\n",
        "    ### HM\n",
        "\n",
        "    self.hm_zero = Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    self.hm_one = ReLU(inplace)\n",
        "    self.hm_two = Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "    ### REG\n",
        "\n",
        "    self.reg_zero = Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    self.reg_one = ReLU(inplace)\n",
        "    self.reg_two = Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "    ### WH\n",
        "\n",
        "    self.wh_zero = Conv2d(64, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
        "    self.wh_one = ReLU(inplace)\n",
        "    self.wh_two = Conv2d(256, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
        "\n",
        "model = NeuralNet()\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0m5yId3jqfI",
        "outputId": "fd906169-1baa-4940-b062-ab670c1b188d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "NeuralNet                                --\n",
              "├─Conv2d: 1-1                            200,704\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "=================================================================\n",
              "Total params: 200,832\n",
              "Trainable params: 200,832\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from tensorflow import keras\n",
        "\n",
        "def test_torch_keras_conversion(torch_layers, keras_layers, input_shape):\n",
        "  pytorch_model = nn.Sequential(*torch_layers)\n",
        "  pytorch_model.eval()\n",
        "  keras_model = keras.Sequential(keras_layers)\n",
        "\n",
        "  # Setup input\n",
        "  input_np = np.random.uniform(0, 1, input_shape)\n",
        "  input_var = Variable(torch.FloatTensor(input_np).permute(0, 3, 1, 2)) # PyTorch's input needs to be reshaped to channels first\n",
        "\n",
        "  print(f\"KERAS INPUT SHAPE: {input_np.shape}\")\n",
        "  print(f\"TORCH INPUT SHAPE: {input_var.shape}\")\n",
        "\n",
        "  # Make predictions:\n",
        "  keras_model_output = keras_model.predict(input_np)\n",
        "  keras_weights = keras_model.get_weights()\n",
        "\n",
        "  # Very hacky code for making sure the weights get transferred properly for the different layers\n",
        "  # Will not work if there are multiple layers in torch_layers / keras_layers (excluding ZeroPadding2D)\n",
        "  if len(keras_weights) > 0:\n",
        "    contains_conv2d = any(isinstance(layer, keras.layers.Conv2D) for layer in keras_layers)\n",
        "    contains_batchnorm = any(isinstance(layer, keras.layers.BatchNormalization) for layer in keras_layers)\n",
        "    if contains_conv2d:\n",
        "      # Transpose weights if conv2d\n",
        "      pytorch_model[0].weight.data = torch.from_numpy(np.transpose(keras_weights[0], [3, 2, 0, 1]))\n",
        "\n",
        "    if contains_batchnorm:\n",
        "      pytorch_model[0].weight.data = torch.from_numpy(keras_weights[0])\n",
        "      pytorch_model[0].bias.data = torch.from_numpy(keras_weights[1])\n",
        "      pytorch_model[0].running_mean.data = torch.from_numpy(keras_weights[2])\n",
        "      pytorch_model[0].running_var.data = torch.from_numpy(keras_weights[3])\n",
        "\n",
        "  pytorch_model_output = pytorch_model(input_var).permute(0, 2, 3, 1).data.numpy() # Reshape back to channels last for comparison\n",
        "\n",
        "  print(pytorch_model_output.shape)\n",
        "  print(keras_model_output.shape)\n",
        "  error = np.max(pytorch_model_output - keras_model_output)\n",
        "  print(f\"Error: {error} is less than 1-e5? {error < 1e-5}\")"
      ],
      "metadata": {
        "id": "oDJzkPXOP7Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONV2D Test\n",
        "test_torch_keras_conversion(\n",
        "    [nn.Conv2d(in_channels = 3, out_channels = 10, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias = False)],\n",
        "    [keras.layers.ZeroPadding2D(padding=(3,3)), keras.layers.Conv2D(filters=10, kernel_size=(7, 7), strides=(2, 2), use_bias=False)],\n",
        "    (1, 64, 64, 3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsp3Br_vS_Qd",
        "outputId": "5a446f42-3d94-462c-998e-72b7e1fd6e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KERAS INPUT SHAPE: (1, 64, 64, 3)\n",
            "TORCH INPUT SHAPE: torch.Size([1, 3, 64, 64])\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "(1, 32, 32, 10)\n",
            "(1, 32, 32, 10)\n",
            "Error: 0.0 is less than 1-e5? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCHNORM TEST\n",
        "test_torch_keras_conversion(\n",
        "    [nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)],\n",
        "    [keras.layers.BatchNormalization(axis=3, momentum=0.1, epsilon=1e-05, center=True, scale=True)],\n",
        "    (1, 32, 32, 64)\n",
        ")"
      ],
      "metadata": {
        "id": "khg5L3VWUJ_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ebcaff-6c14-4463-ff46-5b39ca4ff149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KERAS INPUT SHAPE: (1, 32, 32, 64)\n",
            "TORCH INPUT SHAPE: torch.Size([1, 64, 32, 32])\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "Error: 5.960464477539063e-08 is less than 1-e5? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RELU TEST\n",
        "test_torch_keras_conversion(\n",
        "    [nn.ReLU(inplace=True)],\n",
        "    [keras.layers.ReLU()],\n",
        "    (1, 32, 32, 64)\n",
        ")"
      ],
      "metadata": {
        "id": "nfkmrgBlaHw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bde8a4d-84b6-4895-8ee0-68cef0be329d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KERAS INPUT SHAPE: (1, 32, 32, 64)\n",
            "TORCH INPUT SHAPE: torch.Size([1, 64, 32, 32])\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "Error: 0.0 is less than 1-e5? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAXPOOL TEST\n",
        "test_torch_keras_conversion(\n",
        "    [nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)],\n",
        "    [keras.layers.ZeroPadding2D(padding=1), keras.layers.MaxPool2D(pool_size=3, strides=2)],\n",
        "    (1, 32, 32, 64)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKsrEIcnamCJ",
        "outputId": "4bee6187-3239-42a1-9eb3-664585e7885a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KERAS INPUT SHAPE: (1, 32, 32, 64)\n",
            "TORCH INPUT SHAPE: torch.Size([1, 64, 32, 32])\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Error: 0.0 is less than 1e5? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing individual layer outputs (moved to function above to test other types of layers)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from torch.autograd import Variable\n",
        "from torchinfo import summary\n",
        "\n",
        "TORCH_INPUT_SHAPE = (1, 3, 32, 32) # (BATCH, CHANNEL, WIDTH, HEIGHT)\n",
        "KERAS_INPUT_SHAPE = (1, 32, 32, 3) # (BATCH, WIDTH, HEIGHT, CHANNEL)\n",
        "\n",
        "# Create models\n",
        "pytorch_model = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 10, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias = False))\n",
        "pytorch_model.eval()\n",
        "keras_model = keras.Sequential()\n",
        "keras_model.add(keras.layers.ZeroPadding2D(padding=(3,3)))\n",
        "keras_model.add(keras.layers.Conv2D(filters=10, kernel_size=(7, 7), strides=(2, 2), use_bias=False))\n",
        "\n",
        "# Setup input\n",
        "input_np = np.random.uniform(0, 1, KERAS_INPUT_SHAPE)\n",
        "input_var = Variable(torch.FloatTensor(input_np).permute(0, 3, 1, 2)) # PyTorch's input needs to be reshaped to channels first\n",
        "\n",
        "# Make predictions\n",
        "keras_model_output = keras_model.predict(input_np)\n",
        "keras_weights = keras_model.get_weights()\n",
        "pytorch_model[0].weight.data = torch.from_numpy(np.transpose(keras_weights[0], [3, 2, 0, 1])) # copy weights from keras to pytorch\n",
        "pytorch_model_output = pytorch_model(input_var).permute(0, 2, 3, 1).data.numpy() # Reshape back to channels last for comparison\n",
        "\n",
        "print(f\"TORCH OUTPUT SHAPE: {pytorch_model_output.shape}\")\n",
        "print(f\"KERAS OUTPUT SHAPE: {keras_model_output.shape}\")\n",
        "\n",
        "error = np.max(pytorch_model_output - keras_model_output)\n",
        "print(f\"Error: {error}\")\n",
        "\n",
        "print(\"\\nTORCH MODEL:\")\n",
        "print(summary(pytorch_model))\n",
        "print(\"\\nKERAS MODEL: \")\n",
        "print(keras_model.summary())"
      ],
      "metadata": {
        "id": "KLr61K5-X01a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from .model_parts import CombinationModule\n",
        "\n",
        "class DecNet(nn.Module):\n",
        "    def __init__(self, heads, final_kernel, head_conv, channel):\n",
        "        super(DecNet, self).__init__()\n",
        "        self.dec_c2 = CombinationModule(128, 64, batch_norm=True)\n",
        "        self.dec_c3 = CombinationModule(256, 128, batch_norm=True)\n",
        "        self.dec_c4 = CombinationModule(512, 256, batch_norm=True)\n",
        "        self.heads = heads\n",
        "        for head in self.heads:\n",
        "            classes = self.heads[head]\n",
        "            if head == 'wh':\n",
        "                fc = nn.Sequential(nn.Conv2d(channel, head_conv, kernel_size=7, padding=7//2, bias=True),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.Conv2d(head_conv, classes, kernel_size=7, padding=7 // 2, bias=True))\n",
        "            else:\n",
        "                fc = nn.Sequential(nn.Conv2d(channel, head_conv, kernel_size=3, padding=1, bias=True),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.Conv2d(head_conv, classes, kernel_size=final_kernel, stride=1,\n",
        "                                             padding=final_kernel // 2, bias=True))\n",
        "            if 'hm' in head:\n",
        "                fc[-1].bias.data.fill_(-2.19)\n",
        "            else:\n",
        "                self.fill_fc_weights(fc)\n",
        "\n",
        "            self.__setattr__(head, fc)\n",
        "\n",
        "\n",
        "    def fill_fc_weights(self, layers):\n",
        "        for m in layers.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        c4_combine = self.dec_c4(x[-1], x[-2])\n",
        "        c3_combine = self.dec_c3(c4_combine, x[-3])\n",
        "        c2_combine = self.dec_c2(c3_combine, x[-4])\n",
        "        dec_dict = {}\n",
        "        for head in self.heads:\n",
        "            dec_dict[head] = self.__getattr__(head)(c2_combine)\n",
        "            if 'hm' in head:\n",
        "                dec_dict[head] = torch.sigmoid(dec_dict[head])\n",
        "        return dec_dict"
      ],
      "metadata": {
        "id": "kTR1aQmO23p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_batch_ops import Batch\n",
        "from keras.layers import Conv2D, BatchNormalization, ReLU, Concatenate, UpSampling2D\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define CombinationModule\n",
        "class CombinationModule(keras.layers.Layer):\n",
        "  def __init__(self, filters, **kwargs):\n",
        "    super(CombinationModule, self).__init__(**kwargs)\n",
        "\n",
        "    self.up = keras.models.Sequential([\n",
        "        Conv2D(filters-filters, kernel_size=3, strides=1, padding=\"same\"),\n",
        "        BatchNormalization(),\n",
        "        ReLU()\n",
        "    ])\n",
        "\n",
        "    self.cat_conv = keras.models.Sequential([\n",
        "        Conv2D(filters=filters, kernel_size=1, strides=1),\n",
        "        BatchNormalization(),\n",
        "        ReLU()\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x, encoder_output = inputs\n",
        "\n",
        "    # Upsample x\n",
        "    x = keras.layers.UpSampling2D(size=(2,2))(x)\n",
        "    x = self.up(x)\n",
        "\n",
        "    # Concatenate x and encoder.output\n",
        "    x = Concatenate([x, encoder_output], axis=-1)\n",
        "\n",
        "    # Apply 1x1 convolution\n",
        "    x = self.cat_conv(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "i39frHKM3G1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "_HB-XX835vmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}